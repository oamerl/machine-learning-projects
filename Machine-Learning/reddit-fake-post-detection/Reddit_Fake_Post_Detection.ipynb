{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oamerl/machine-learning-projects/blob/main/Machine-Learning/reddit-fake-post-detection/Reddit_Fake_Post_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment Summary**"
      ],
      "metadata": {
        "id": "jaI6wT8vI7Zx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the design of all models we will be using TF-IDF as the vectorizer and using a separate predefined validation set for the validation. We will be using two different text preprocessing techniques we will first start with stemming using which we will try three models, two logistic regression models (one with word n-gram and one with character n-gram), and one XGboost model. In the design of these three models we will be using random search for hyperparameters tuning for both the vectorizer and the models themselves.\n",
        "Then next we will re-process the data using lemmatization to see if the performance will differ from the case of using stemming and will assess the performance on two models one is logistic regression with hyperparameters tuning while the other is XGboost model but will use the previously found hyperparameters in sake of time saving.\n"
      ],
      "metadata": {
        "id": "_7pG59YJJD0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.** Data and Libraries Importing üìã"
      ],
      "metadata": {
        "id": "ds_FQDtH6PUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing needed libraries\n"
      ],
      "metadata": {
        "id": "jg6HvZJlYYOS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVsNhUFofGO_"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pickle\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import holoviews as hv\n",
        "import nltk\n",
        "from bokeh.io import output_notebook\n",
        "output_notebook()\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# some settings for pandas and hvplot\n",
        "\n",
        "pd.options.display.max_columns = 100\n",
        "pd.options.display.max_rows = 300\n",
        "pd.options.display.max_colwidth = 100\n",
        "np.set_printoptions(threshold=2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XY5Oq_eZfGPA"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the data"
      ],
      "metadata": {
        "id": "LJa0n4oWYbgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(\"/content/xy_train.csv\", sep=\",\", na_values=[\"\"]) # reading the training dataset file\n",
        "test_data = pd.read_csv(\"/content/x_test.csv\", sep=\",\", na_values=[\"\"]) # reading the testing dataset file"
      ],
      "metadata": {
        "id": "fidMS_wpmrT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_oLnG-znQwVD",
        "outputId": "a7ac7506-ed05-42b3-9697-042200d1ba5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id  \\\n",
              "0      265723   \n",
              "1      284269   \n",
              "2      207715   \n",
              "3      551106   \n",
              "4        8584   \n",
              "...       ...   \n",
              "59995   70046   \n",
              "59996  189377   \n",
              "59997   93486   \n",
              "59998  140950   \n",
              "59999   34509   \n",
              "\n",
              "                                                                                                      text  \\\n",
              "0      A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "1      British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "2      In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "3      Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "4      Obama to Nation: ËÅô\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "...                                                                                                    ...   \n",
              "59995                Finish Sniper Simo HÁõ≤yhÁõ≤ during the invasion of Finland by the USSR (1939, colorized)   \n",
              "59996                Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back   \n",
              "59997                Is It Safe To Smoke Marijuana During Pregnancy? YouÈà•Ê™á Be Surprised Of The Answer | no   \n",
              "59998                Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)   \n",
              "59999                Jeff Bridges Releasing Èà•Ê•Ωleeping Tapes,Èà•?a New Album Designed to Help You Fall Asleep   \n",
              "\n",
              "       label  \n",
              "0          0  \n",
              "1          0  \n",
              "2          0  \n",
              "3          0  \n",
              "4          0  \n",
              "...      ...  \n",
              "59995      0  \n",
              "59996      1  \n",
              "59997      0  \n",
              "59998      0  \n",
              "59999      1  \n",
              "\n",
              "[60000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a90bb4db-63d8-49aa-b7e1-e5a6f33cab31\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>265723</td>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>284269</td>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>207715</td>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>551106</td>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8584</td>\n",
              "      <td>Obama to Nation: ËÅô\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>70046</td>\n",
              "      <td>Finish Sniper Simo HÁõ≤yhÁõ≤ during the invasion of Finland by the USSR (1939, colorized)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>189377</td>\n",
              "      <td>Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>93486</td>\n",
              "      <td>Is It Safe To Smoke Marijuana During Pregnancy? YouÈà•Ê™á Be Surprised Of The Answer | no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>140950</td>\n",
              "      <td>Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>34509</td>\n",
              "      <td>Jeff Bridges Releasing Èà•Ê•Ωleeping Tapes,Èà•?a New Album Designed to Help You Fall Asleep</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows √ó 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a90bb4db-63d8-49aa-b7e1-e5a6f33cab31')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a90bb4db-63d8-49aa-b7e1-e5a6f33cab31 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a90bb4db-63d8-49aa-b7e1-e5a6f33cab31');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3.** Data Cleaning and Pre-processing üßº"
      ],
      "metadata": {
        "id": "yD5ixpOuDVdL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will first start with typicall steps that we usually do which is conserving the record id as the dataframe index and checking the target label range of values"
      ],
      "metadata": {
        "id": "4T0qCW_fNFdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.set_index('id', inplace = True) # setting the index of the training set dataframe to be the coulmn named \"id\" such that we don't lose it.\n",
        "test_data.set_index('id', inplace = True) # setting the index of the testing set dataframe to be the coulmn named \"id\" such that we don't lose it."
      ],
      "metadata": {
        "id": "6FQ8iPnoTvP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking target label"
      ],
      "metadata": {
        "id": "ONZUDvCeNWrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[\"label\"].value_counts()) # checking the values count of the target label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfRRb6oVUOVX",
        "outputId": "3b78df43-6209-47b1-b71b-4147997ec5df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    32172\n",
            "1    27596\n",
            "2      232\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We notice that there is a label of value 2 which is inconsistent with the problem definition of classifing whether fake or not so will drop records(titles) corresponding to this label"
      ],
      "metadata": {
        "id": "_82sD2XIMQVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[train_data.label == 2].index # checkin if we are getting the index correctly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TVy0f2JUwpw",
        "outputId": "6050d8d9-4afa-4488-c75f-b4903aca1dbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([540454, 342238, 552146, 549212, 398378, 337016, 357384, 513998,\n",
              "            448641, 378658,\n",
              "            ...\n",
              "            398826,  60959, 186950, 420136,  89505, 219497,  54937, 505566,\n",
              "            288391,  99749],\n",
              "           dtype='int64', name='id', length=232)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.drop(train_data[train_data.label == 2].index, inplace=True) # dropping records of label = 2\n"
      ],
      "metadata": {
        "id": "TSiXhiwEUk4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[\"label\"].value_counts()) # checking the values count of the target label after dropping inconsistent values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqALwokZVbk3",
        "outputId": "b0c594b2-d477-4a82-aeb7-ad82ff3ceef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    32172\n",
            "1    27596\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.1-** Text cleaning function definition"
      ],
      "metadata": {
        "id": "_uGcXa-TYLwZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWrWpOQVfGPD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3edd03c7-c308-4694-d4a1-577cb80507df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "\n",
        "def clean_text(text, root_form = \"stemming\", for_embedding=False):\n",
        "    \"\"\" steps:\n",
        "        - remove any html tags (< /br> often found)\n",
        "        - Keep only ASCII + European Chars and whitespace, no digits\n",
        "        - remove single letter chars\n",
        "        - convert all whitespaces (tabs etc.) to single wspace\n",
        "        if not for embedding (but e.g. tdf-idf):\n",
        "        - all lowercase\n",
        "        - remove stopwords, punctuation and stemm\n",
        "    \"\"\"\n",
        "    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n",
        "    RE_TAGS = re.compile(r\"<[^>]+>\")\n",
        "    RE_ASCII = re.compile(r\"[^A-Za-z ]\", re.IGNORECASE)\n",
        "    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-z]\\b\", re.IGNORECASE)\n",
        "    if for_embedding:\n",
        "        # Keep punctuation\n",
        "        RE_ASCII = re.compile(r\"[^A-Za-z,.!? ]\", re.IGNORECASE)\n",
        "        RE_SINGLECHAR = re.compile(r\"\\b[A-Za-z,.!?]\\b\", re.IGNORECASE)\n",
        "\n",
        "    text = re.sub(RE_TAGS, \" \", text)\n",
        "    text = re.sub(RE_ASCII, \" \", text)\n",
        "    text = re.sub(RE_SINGLECHAR, \" \", text)\n",
        "    text = re.sub(RE_WSPACE, \" \", text)\n",
        "\n",
        "    word_tokens = word_tokenize(text) # returns a tokenized copy of text as a list\n",
        "    words_tokens_lower = [word.lower() for word in word_tokens]\n",
        "\n",
        "    if for_embedding:\n",
        "        # no stemming, lowering and punctuation / stop words removal\n",
        "        words_filtered = word_tokens\n",
        "    else:\n",
        "        if root_form == \"stemming\":\n",
        "            words_filtered = [stemmer.stem(word) for word in words_tokens_lower if word not in stop_words]\n",
        "        elif root_form == \"lemmatization\":\n",
        "            words_filtered = [lemmatizer.lemmatize(word) for word in words_tokens_lower if word not in stop_words]\n",
        "\n",
        "    text_clean = \" \".join(words_filtered)\n",
        "    return text_clean"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking if *Stemming* is working correctly"
      ],
      "metadata": {
        "id": "NPGO7WUd0a5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text(\"√©ÀÜ¬•√¶¬∑¬≤e are common people doing an exceptional job / Heroes in Colombia do exist√©ÀÜ¬•?[Modern]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "08tvbCaHb5U9",
        "outputId": "28a16d83-fe2b-40ef-d484-886c9d5d6598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'common peopl except job hero colombia exist modern'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking if *Lemmatization* is working correctly"
      ],
      "metadata": {
        "id": "7Qt2zIkh0eNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text(\"√©ÀÜ¬•√¶¬∑¬≤e are common people doing an exceptional job / Heroes in Colombia do exist√©ÀÜ¬•?[Modern]\", root_form = \"lemmatization\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vKAOtD1Vz7XQ",
        "outputId": "037c9fe1-5ba1-4395-d592-884c05fc3547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'common people exceptional job hero colombia exist modern'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making 2 copies of the original dataframe before applying any changes, one copy for stemming and one for lemmatization preprocessing"
      ],
      "metadata": {
        "id": "wY-7aiMT2gBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_clean = train_data.copy() # training data to be used in stemming case\n",
        "train_data_clean_lemm = train_data.copy() # training data to be used in lemmatization case"
      ],
      "metadata": {
        "id": "kSWny1NscbI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_lemm = test_data.copy() # testing data to be used in lemmatization case\n",
        "# original test_data will be used in case of stemming"
      ],
      "metadata": {
        "id": "wkTpGlJz4oqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_clean.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "7o36C7gxcig3",
        "outputId": "393b0098-7a3b-4a5d-87ad-b6adbd00c78f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                       text  \\\n",
              "id                                                                                                            \n",
              "265723  A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "284269  British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "207715  In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "551106  Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "8584    Obama to Nation: ËÅô\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "\n",
              "        label  \n",
              "id             \n",
              "265723      0  \n",
              "284269      0  \n",
              "207715      0  \n",
              "551106      0  \n",
              "8584        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86744da7-e824-402d-b8d5-2e6c8e21d182\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>265723</th>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284269</th>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207715</th>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>551106</th>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8584</th>\n",
              "      <td>Obama to Nation: ËÅô\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86744da7-e824-402d-b8d5-2e6c8e21d182')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86744da7-e824-402d-b8d5-2e6c8e21d182 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86744da7-e824-402d-b8d5-2e6c8e21d182');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.2-** Stemming preprocessing"
      ],
      "metadata": {
        "id": "WsMSo9fq0nsl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As discussed in the \"Experiment Summary\" in the introduction, we will first use stemming as our inflected words root form obtainer technique and will build with it three models and then will reprocess the data again later using the lemmatization and build another two models.  "
      ],
      "metadata": {
        "id": "HR8AghaXOJ40"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reNh5TLbfGPF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81818013-996c-4421-932f-190b6eb695ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 25 s, sys: 98 ms, total: 25.1 s\n",
            "Wall time: 29.6 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Training clean titles (stemming used)\n",
        "train_data_clean[\"comment_clean\"] = train_data_clean[\"text\"].map(lambda x: clean_text(x, root_form = \"stemming\", for_embedding=False) if isinstance(x, str) else x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing clean titles (stemming used)\n",
        "test_data[\"comment_clean\"] = test_data[\"text\"].map(lambda x: clean_text(x, root_form = \"stemming\", for_embedding=False) if isinstance(x, str) else x)"
      ],
      "metadata": {
        "id": "cFCy4zlof3w6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_clean.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "UWFrMmDyddUk",
        "outputId": "84c4dc14-46c9-4862-96fc-03ed075f7116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                       text  \\\n",
              "id                                                                                                            \n",
              "265723  A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "284269  British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "207715  In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "551106  Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "8584    Obama to Nation: ËÅô\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "...                                                                                                     ...   \n",
              "70046                 Finish Sniper Simo HÁõ≤yhÁõ≤ during the invasion of Finland by the USSR (1939, colorized)   \n",
              "189377                Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back   \n",
              "93486                 Is It Safe To Smoke Marijuana During Pregnancy? YouÈà•Ê™á Be Surprised Of The Answer | no   \n",
              "140950                Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)   \n",
              "34509                 Jeff Bridges Releasing Èà•Ê•Ωleeping Tapes,Èà•?a New Album Designed to Help You Fall Asleep   \n",
              "\n",
              "        label  \\\n",
              "id              \n",
              "265723      0   \n",
              "284269      0   \n",
              "207715      0   \n",
              "551106      0   \n",
              "8584        0   \n",
              "...       ...   \n",
              "70046       0   \n",
              "189377      1   \n",
              "93486       0   \n",
              "140950      0   \n",
              "34509       1   \n",
              "\n",
              "                                                                                              comment_clean  \n",
              "id                                                                                                           \n",
              "265723  group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...  \n",
              "284269  british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...  \n",
              "207715  goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatlant...  \n",
              "551106  happi birthday bob barker price right host like rememb man said ave pet spay neuter fuckincorpor...  \n",
              "8584    obama nation innoc cop unarm young black men die magic johnson jimbobshawobodob olymp athlet sho...  \n",
              "...                                                                                                     ...  \n",
              "70046                                                        finish sniper simo yh invas finland ussr color  \n",
              "189377                                               nigerian princ scam took kansa man year later get back  \n",
              "93486                                                          safe smoke marijuana pregnanc surpris answer  \n",
              "140950                                               julius caesar upon realiz everyon room knife except bc  \n",
              "34509                                         jeff bridg releas leep tape new album design help fall asleep  \n",
              "\n",
              "[59768 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db12a68e-ab39-4628-a6d7-80ddb8c4aa57\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>comment_clean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>265723</th>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0</td>\n",
              "      <td>group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284269</th>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0</td>\n",
              "      <td>british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207715</th>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0</td>\n",
              "      <td>goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatlant...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>551106</th>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>happi birthday bob barker price right host like rememb man said ave pet spay neuter fuckincorpor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8584</th>\n",
              "      <td>Obama to Nation: ËÅô\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0</td>\n",
              "      <td>obama nation innoc cop unarm young black men die magic johnson jimbobshawobodob olymp athlet sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70046</th>\n",
              "      <td>Finish Sniper Simo HÁõ≤yhÁõ≤ during the invasion of Finland by the USSR (1939, colorized)</td>\n",
              "      <td>0</td>\n",
              "      <td>finish sniper simo yh invas finland ussr color</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189377</th>\n",
              "      <td>Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back</td>\n",
              "      <td>1</td>\n",
              "      <td>nigerian princ scam took kansa man year later get back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93486</th>\n",
              "      <td>Is It Safe To Smoke Marijuana During Pregnancy? YouÈà•Ê™á Be Surprised Of The Answer | no</td>\n",
              "      <td>0</td>\n",
              "      <td>safe smoke marijuana pregnanc surpris answer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140950</th>\n",
              "      <td>Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)</td>\n",
              "      <td>0</td>\n",
              "      <td>julius caesar upon realiz everyon room knife except bc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34509</th>\n",
              "      <td>Jeff Bridges Releasing Èà•Ê•Ωleeping Tapes,Èà•?a New Album Designed to Help You Fall Asleep</td>\n",
              "      <td>1</td>\n",
              "      <td>jeff bridg releas leep tape new album design help fall asleep</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59768 rows √ó 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db12a68e-ab39-4628-a6d7-80ddb8c4aa57')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db12a68e-ab39-4628-a6d7-80ddb8c4aa57 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db12a68e-ab39-4628-a6d7-80ddb8c4aa57');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop when any of x \"the cleaned title\" is missing\n",
        "train_data_clean = train_data_clean[(train_data_clean[\"comment_clean\"] != \"\") & (train_data_clean[\"comment_clean\"] != \"null\")]"
      ],
      "metadata": {
        "id": "YjAfBW2ReT1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_clean.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5PUAdekebJm",
        "outputId": "4f4f22cc-32ed-4792-c12e-5c3094d6f921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59758, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uncleaned title column drop"
      ],
      "metadata": {
        "id": "On5et_KjP8vG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove column name 'text' which is the uncleaned title from training set\n",
        "train_data_clean = train_data_clean.drop(['text'], axis=1)\n",
        "\n",
        "# Remove column name 'text' which is the uncleaned title from testing set\n",
        "test_data = test_data.drop(['text'], axis=1)"
      ],
      "metadata": {
        "id": "ZHCo4Hlce27I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_clean.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "qbucS6_8eatS",
        "outputId": "0f06c247-69da-4a9c-8148-81435e3b8427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        label  \\\n",
              "id              \n",
              "265723      0   \n",
              "284269      0   \n",
              "\n",
              "                                                                                              comment_clean  \n",
              "id                                                                                                           \n",
              "265723  group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...  \n",
              "284269  british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1313946-ccb9-4248-924f-10ffe90544f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>comment_clean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>265723</th>\n",
              "      <td>0</td>\n",
              "      <td>group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284269</th>\n",
              "      <td>0</td>\n",
              "      <td>british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1313946-ccb9-4248-924f-10ffe90544f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f1313946-ccb9-4248-924f-10ffe90544f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f1313946-ccb9-4248-924f-10ffe90544f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_clean.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC85LCZBfjyx",
        "outputId": "d056146c-d548-4881-8cf3-5b1ee9038606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 59758 entries, 265723 to 34509\n",
            "Data columns (total 2 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   label          59758 non-null  int64 \n",
            " 1   comment_clean  59758 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 1.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We thought of filtering the records based on the length of the title but we didn't proceed with the idea and left these titles lengths for later reference if needed."
      ],
      "metadata": {
        "id": "0kKNHoHlQDkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_clean[\"comment_clean\"].str.len()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhO6rAw0k_Y0",
        "outputId": "5a5a4714-e16d-40fd-ecb9-ceec32d8115a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "265723    12353\n",
              "284269    11837\n",
              "207715    11024\n",
              "551106     9480\n",
              "8584       9453\n",
              "          ...  \n",
              "70046        46\n",
              "189377       54\n",
              "93486        44\n",
              "140950       54\n",
              "34509        61\n",
              "Name: comment_clean, Length: 59758, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "titles_length = [len(title) for title in train_data_clean['comment_clean']]"
      ],
      "metadata": {
        "id": "gibREOwqgtC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titles_length"
      ],
      "metadata": {
        "id": "1H6_H2iMjYZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"maximum title length:\", max(titles_length))\n",
        "print(\"minimum title length:\", min(titles_length))\n",
        "average = sum(titles_length)/len(titles_length)\n",
        "print(\"average title length:\", average)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbXRwjqkiRAK",
        "outputId": "a3f121d2-b1bd-4728-fbc5-b7a9355bfce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maximum title length: 12353\n",
            "minimum title length: 2\n",
            "average title length: 77.80586699688745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_data_clean[\"comment_clean\"] = train_data_clean.loc[train_data_clean[\"comment_clean\"].str.len() > 20, \"comment_clean\"]\n"
      ],
      "metadata": {
        "id": "0QgAbWFwjoJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.3-** Descriptive analysis"
      ],
      "metadata": {
        "id": "fsfi1-IelVHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bokeh.models import NumeralTickFormatter\n",
        "# Word Frequency of most common words\n",
        "word_freq = pd.Series(\" \".join(train_data_clean[\"comment_clean\"]).split()).value_counts()\n",
        "word_freq[1:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFflsc5nlUQq",
        "outputId": "7f945f7f-85fc-4df6-aa56-dd273e56efda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "one      3285\n",
              "like     3128\n",
              "new      2998\n",
              "look     2847\n",
              "color    2737\n",
              "man      2729\n",
              "get      2602\n",
              "trump    2578\n",
              "say      2347\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list most uncommon words\n",
        "word_freq[-10:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L93OiGRdlnv4",
        "outputId": "b76fc599-1644-42d2-9682-d6d2fdb7b176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "angriff     1\n",
              "delusion    1\n",
              "wane        1\n",
              "undament    1\n",
              "miku        1\n",
              "hatsun      1\n",
              "nfler       1\n",
              "hicock      1\n",
              "mccall      1\n",
              "wahr        1\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of ratings\n",
        "train_data_clean[\"label\"].value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BJy2vnUl2HE",
        "outputId": "33a7f108-09f0-4b48-fc5b-c76690f1fa93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.538221\n",
              "1    0.461779\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.4-** Division of training set into training and validation and decoupling the features from the labels"
      ],
      "metadata": {
        "id": "GVj1scf_nUwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import PredefinedSplit\n",
        "\n",
        "# split the original training set to a train and a validation set - 25% of data as validation\n",
        "train, valid = train_test_split(train_data_clean, stratify=train_data_clean['label'], random_state=1, test_size=0.25, shuffle=True)\n",
        "\n",
        "X_train = train[\"comment_clean\"]\n",
        "y_train = train[\"label\"]\n",
        "\n",
        "X_valid = valid[\"comment_clean\"]\n",
        "y_valid = valid[\"label\"]\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_valid.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iry2TCWSnbg0",
        "outputId": "679e7aca-7f72-4c43-e1b2-82cc8bec3511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(44818,)\n",
            "(14940,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "validation data indicies"
      ],
      "metadata": {
        "id": "LDcnWaJf5VnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list where train data indices are -1 and validation data indices are 0\n",
        "split_index = [-1 if x in X_train.index else 0 for x in train_data_clean.index]\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "pds = PredefinedSplit(test_fold = split_index)"
      ],
      "metadata": {
        "id": "98GmqAMA2QXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "0elI--NtwrE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_tr = train_data_clean[\"label\"] # target label series\n",
        "X_tr = train_data_clean[\"comment_clean\"] # training features df"
      ],
      "metadata": {
        "id": "TikV4MyQ4Nm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5aogi-OVe3f",
        "outputId": "e3c35ab0-0fd8-446f-81c5-fb36dd4dd90d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "265723    group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...\n",
              "284269    british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...\n",
              "Name: comment_clean, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4.** Models Training and Evaluation üìà"
      ],
      "metadata": {
        "id": "wtHAvXOy5mkl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a general followed approach in the notebook for limiting the hyper-parameters search space to reduce tuning time, we first optimize the feature creation (vectorization) step through trying different values for ngram, max_df and min_df, then we use these values for the vectorization and retune again but now searching for the model's best hyperparameters.\n",
        "Although this may lead to sub-optimal values as a more suitable approach would be tunining all hyperparameters toghether but for time sake we will tolerate this sub-optimality."
      ],
      "metadata": {
        "id": "kG_G-ijr6hHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.1-** Case 1: Models trained on data preprocessed using ***Stemming***"
      ],
      "metadata": {
        "id": "5_A62LKI8Ger"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1 Logistic Regression with TF-IDF vectorization (analyzer=word) and random search as hyperparameter tuner"
      ],
      "metadata": {
        "id": "umxXoBw9fx3x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizing the feature creation (vectorization) step through trying different values for ngram, max_df and min_df where the last two parameters set an upper and lower limit for word frequencies."
      ],
      "metadata": {
        "id": "xX4RG3UZifHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# feature creation and modelling in a single function\n",
        "# combine the victorizer with the model as a full tunable pipeline\n",
        "# we gave them a name so we can set their hyperparameters\n",
        "pipe = Pipeline(\n",
        "        steps = [(\"tfidf\", TfidfVectorizer(analyzer=\"word\")),\n",
        "                 (\"logreg\", LogisticRegression(n_jobs=-1))]\n",
        ")\n",
        "\n",
        "# define parameter space to test\n",
        "# hyperparameters search space of both the model and preprocessing\n",
        "params = {\n",
        "    # victorizer hyperparameters (5*5*3 75 combination)\n",
        "    \"tfidf__ngram_range\": ((1, 2), (1, 3),(1,4)),\n",
        "    \"tfidf__max_df\": [0.5, 0.6, 0.7, 0.8, 0.9],\n",
        "    \"tfidf__min_df\": [5, 10, 20, 30, 50]\n",
        "}\n",
        "\n",
        "# logistic regression random search instance\n",
        "pipe_clf = RandomizedSearchCV(pipe, # pipeline containing the victorizer and model\n",
        "                              params, # pipeline hyperparameters\n",
        "                              cv=pds, # predefined split\n",
        "                              scoring=\"roc_auc\", # scoring metric used to evaluate the validation data with it\n",
        "                              n_iter=37, # number of trials (hyperparameters combinations to try)\n",
        "                              n_jobs=-1, # number of concurrent threads -1 means using all processors\n",
        "                              verbose=1,)\n",
        "\n",
        "# model fitting and training using the training data (will use the optimal hyperparameters that will be found)\n",
        "# here we still use X_tr; but the randomized search model\n",
        "# will use our predefined split internally to determine\n",
        "# which sample belongs to the validation set\n",
        "pipe_clf.fit(X_tr, y_tr)\n",
        "pickle.dump(pipe_clf, open(\"./pipeline_clf_tfidf.pck\", \"wb\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYABKH7_vhJn",
        "outputId": "a9ebe3b9-0300-4abd-a657-4be9b58a089d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 37 candidates, totalling 37 fits\n",
            "CPU times: user 6.48 s, sys: 413 ms, total: 6.89 s\n",
            "Wall time: 2min 8s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('best score {}'.format(pipe_clf.best_score_)) # getting the best validation AUC score\n",
        "print('best hyperparameters {}'.format(pipe_clf.best_params_)) # getting the optimal hyperparameters values found"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXg9gNiOyB1S",
        "outputId": "d58d369f-4024-45fc-a948-cb618ebade98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.869891854975242\n",
            "best hyperparameters {'tfidf__ngram_range': (1, 3), 'tfidf__min_df': 5, 'tfidf__max_df': 0.8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, using this best parameters for TF-IDF we can search for optimal parameters for the LogisticRegression classifier:"
      ],
      "metadata": {
        "id": "VdDty7BG6qr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# feature creation and modelling in a single function\n",
        "# combine the victorizer with the model as a full tunable pipeline\n",
        "# we gave them a name so we can set their hyperparameters\n",
        "pipe = Pipeline(\n",
        "        steps = [(\"tfidf\", TfidfVectorizer(analyzer=\"word\")),\n",
        "                 (\"logreg\", LogisticRegression(n_jobs=-1))]\n",
        ")\n",
        "\n",
        "# define parameter space to test\n",
        "# hyperparameters search space of both the model and preprocessing\n",
        "params = {\n",
        "    # victorizer hyperparameters\n",
        "    \"tfidf__ngram_range\": [(1, 3)], # pipe_clf.best_params_[\"tfidf__ngram_range\"]\n",
        "    \"tfidf__max_df\": [0.8], # pipe_clf.best_params_[\"tfidf__max_df\"]\n",
        "    \"tfidf__min_df\": [5], # pipe_clf.best_params_[\"tfidf__min_df\"]\n",
        "    # model hyperparameters\n",
        "    'logreg__penalty': [\"l2\"],\n",
        "    'logreg__C': [0.01, 0.1, 1,10],\n",
        "    'logreg__max_iter': [10000],\n",
        "    'logreg__solver': [\"newton-cholesky\", \"saga\", \"lbfgs\", \"liblinear\"]\n",
        "}\n",
        "\n",
        "# logistic regression random search instance\n",
        "pipe_logreg_clf = RandomizedSearchCV(pipe, # pipeline containing the victorizer and model\n",
        "                                    params, # pipeline hyperparameters\n",
        "                                    cv=pds, # predefined split\n",
        "                                    scoring=\"roc_auc\", # scoring metric used to evaluate the validation data with it\n",
        "                                    n_iter=10, # number of trials (hyperparameters combinations to try)\n",
        "                                    n_jobs=-1, # number of concurrent threads -1 means using all processors\n",
        "                                    verbose=1,)\n",
        "\n",
        "# model fitting and training using the training data (will use the optimal hyperparameters that will be found)\n",
        "# here we still use X_tr; but the randomized search model will use our predefined split internally to determine\n",
        "# which sample belongs to the validation set\n",
        "pipe_logreg_clf.fit(X_tr, y_tr)\n",
        "pickle.dump(pipe_logreg_clf, open(\"./pipeline_clf_logreg.pck\", \"wb\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWo5N_N66yAy",
        "outputId": "bd9c5c87-3c76-4d73-b260-068326ab4e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
            "CPU times: user 8.03 s, sys: 776 ms, total: 8.8 s\n",
            "Wall time: 9min 51s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('best score {}'.format(pipe_logreg_clf.best_score_)) # getting the best validation AUC score\n",
        "\n",
        "best_params_logreg = pipe_logreg_clf.best_params_\n",
        "print('best hyperparameters {}'.format(best_params_logreg)) # getting the optimal hyperparameters values found"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGWz2f-W7fGL",
        "outputId": "2807e317-a462-4357-ed4e-b802e9f38d27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.8698897639379309\n",
            "best hyperparameters {'tfidf__ngram_range': (1, 3), 'tfidf__min_df': 5, 'tfidf__max_df': 0.8, 'logreg__solver': 'lbfgs', 'logreg__penalty': 'l2', 'logreg__max_iter': 10000, 'logreg__C': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training on whole dataset"
      ],
      "metadata": {
        "id": "VcyykHJMaX1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.set_params(**best_params_logreg).fit(X_tr, y_tr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "_PIg-xXtZv7M",
        "outputId": "21507ec0-d085-4baf-f60f-8d4620ce9213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf',\n",
              "                 TfidfVectorizer(max_df=0.8, min_df=5, ngram_range=(1, 3))),\n",
              "                ('logreg', LogisticRegression(C=1, max_iter=10000, n_jobs=-1))])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
              "                 TfidfVectorizer(max_df=0.8, min_df=5, ngram_range=(1, 3))),\n",
              "                (&#x27;logreg&#x27;, LogisticRegression(C=1, max_iter=10000, n_jobs=-1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
              "                 TfidfVectorizer(max_df=0.8, min_df=5, ngram_range=(1, 3))),\n",
              "                (&#x27;logreg&#x27;, LogisticRegression(C=1, max_iter=10000, n_jobs=-1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.8, min_df=5, ngram_range=(1, 3))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, max_iter=10000, n_jobs=-1)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing (Predictions of test set)"
      ],
      "metadata": {
        "id": "wtyjQZnsV37g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame()\n",
        "submission['id'] = test_data.index\n",
        "submission['label'] = pipe.predict_proba(test_data['comment_clean'])[:,1]\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "Lb6eQd4cZHE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations and trial summary"
      ],
      "metadata": {
        "id": "E4w_tZbsVq0u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Aspect**                                                | **Comment**                                                                                                                                                                                |\n",
        "|-----------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| _1- Model type_                                           | Logistic Regression                                                                                                                                                                        |\n",
        "| _2- Root-form preprocessing_                              | Stemming                                                                                                                                                                                   |\n",
        "| _3- Vectorizer_                                           | TF-IDF (word n-gram)                                                                                                                                                                       |\n",
        "| _4- Hyperparameters tuner_                                | Randomized Search (using predefined validation set)                                                                                                                                        |\n",
        "| _5- Vectorizer hyperparameters space_                     | \"tfidf__ngram_range\": ((1, 2), (1, 3),(1,4)),<br>\"tfidf__max_df\": [0.5, 0.6, 0.7, 0.8, 0.9],<br>\"tfidf__min_df\": [5, 10, 20, 30, 50]                                                       |\n",
        "| _6- Model hyperparameters space_                          | 'logreg__penalty': [\"l2\"],<br>'logreg__C': [0.01, 0.1, 1,10],<br>'logreg__max_iter': [10000],<br>'logreg__solver': [\"newton-cholesky\", \"saga\", \"lbfgs\", \"liblinear\"]                       |\n",
        "| _7- Optimal hyperparameters_                             | 'tfidf__ngram_range': (1, 3),<br>'tfidf__min_df': 5,<br>'tfidf__max_df': 0.8,<br>'logreg__solver': 'lbfgs', <br>'logreg__penalty': 'l2', <br>'logreg__max_iter': 10000, <br>'logreg__C': 1 |\n",
        "| _8- AUC score predefined validation set_                  | 0.8699                                                                                                                                                                                     |\n",
        "| _9- AUC score on kaggle test set (public)_                | 0.8376                                                                                                                                                                                     |\n",
        "| _10- Observed performance and thoughts on it_             | Here we started with logistic regression model as it usually fits most of the problems nicely while being not a complex model.<br> We can notice that the logistic regression is having a good performance and not overfitting, but we think we can further improve <br> the score if we used another hyperparameter tuner than Randomized Seacrh say Bayesian Search or Grid search to obtain better <br>hyperparameters as there is a potential that there are other values that could fit better as the model is already having acceptable metrics.                                                                                                                                                                                         |\n",
        "| _11- Reason for changes (if any) and plan for next trial_ | Next we still use logistic regression model but will try using character level n-grams although we expect it to have lower performance.                                                                                                                                                                                       |"
      ],
      "metadata": {
        "id": "LR9Oq9mIa_fR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2 Logistic Regression with TF-IDF vectorization (analyzer is character-level) and random search as hyperparameter tuner"
      ],
      "metadata": {
        "id": "6uTJlBFbx6eb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizing the feature creation (vectorization) step through trying different values for ngram, max_df and min_df where the last two parameters set an upper and lower limit for word frequencies."
      ],
      "metadata": {
        "id": "e7rFPGJ5x6eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# feature creation and modelling in a single function\n",
        "# combine the victorizer with the model as a full tunable pipeline\n",
        "# we gave them a name so we can set their hyperparameters\n",
        "pipe = Pipeline(\n",
        "        steps = [(\"tfidf\", TfidfVectorizer(analyzer=\"char\")),\n",
        "                 (\"logreg\", LogisticRegression(n_jobs=-1))]\n",
        ")\n",
        "\n",
        "# define parameter space to test\n",
        "# hyperparameters search space of both the model and preprocessing\n",
        "params = {\n",
        "    # victorizer hyperparameters (5*5*3 75 combination)\n",
        "    \"tfidf__ngram_range\": ((1, 2), (1, 3),(1,4)),\n",
        "    \"tfidf__max_df\": [0.5, 0.6, 0.7, 0.8, 0.9],\n",
        "    \"tfidf__min_df\": [5, 10, 20, 30, 50]\n",
        "}\n",
        "\n",
        "# logistic regression random search instance\n",
        "pipe_clf = RandomizedSearchCV(pipe, # pipeline containing the victorizer and model\n",
        "                              params, # pipeline hyperparameters\n",
        "                              cv=pds, # predefined split\n",
        "                              scoring=\"roc_auc\", # scoring metric used to evaluate the validation data with it\n",
        "                              n_iter=37, # number of trials (hyperparameters combinations to try)\n",
        "                              n_jobs=-1, # number of concurrent threads -1 means using all processors\n",
        "                              verbose=1,)\n",
        "\n",
        "# model fitting and training using the training data (will use the optimal hyperparameters that will be found)\n",
        "# here we still use X_tr; but the randomized search model\n",
        "# will use our predefined split internally to determine\n",
        "# which sample belongs to the validation set\n",
        "pipe_clf.fit(X_tr, y_tr)\n",
        "pickle.dump(pipe_clf, open(\"./pipeline_clf_tfidf.pck\", \"wb\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff7556c-7827-4779-cde0-f44e71216030",
        "id": "HSpHz8cKr5lj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 37 candidates, totalling 37 fits\n",
            "CPU times: user 14.1 s, sys: 1.31 s, total: 15.4 s\n",
            "Wall time: 5min 52s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('best score {}'.format(pipe_clf.best_score_)) # getting the best validation AUC score\n",
        "print('best hyperparameters {}'.format(pipe_clf.best_params_)) # getting the optimal hyperparameters values found"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41b9d773-ef57-46a5-b0a0-3a7dfbddc101",
        "id": "LxOCwujLr5ll"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.8511221452586296\n",
            "best hyperparameters {'tfidf__ngram_range': (1, 4), 'tfidf__min_df': 5, 'tfidf__max_df': 0.7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, using this best parameters for TF-IDF we can search for optimal parameters for the LogisticRegression classifier:"
      ],
      "metadata": {
        "id": "Lld_og-fr5lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# feature creation and modelling in a single function\n",
        "# combine the victorizer with the model as a full tunable pipeline\n",
        "# we gave them a name so we can set their hyperparameters\n",
        "pipe = Pipeline(\n",
        "        steps = [(\"tfidf\", TfidfVectorizer(analyzer=\"char\")),\n",
        "                 (\"logreg\", LogisticRegression(n_jobs=2))]\n",
        ")\n",
        "\n",
        "# define parameter space to test\n",
        "# hyperparameters search space of both the model and preprocessing\n",
        "params = {\n",
        "    # victorizer hyperparameters\n",
        "    \"tfidf__ngram_range\": [(1, 4)],\n",
        "    \"tfidf__max_df\": [0.7],\n",
        "    \"tfidf__min_df\": [5],\n",
        "    # model hyperparameters\n",
        "    'logreg__penalty': [\"l2\"],\n",
        "    'logreg__C': [0.01, 0.1, 1, 10],\n",
        "    'logreg__max_iter': [10000],\n",
        "    'logreg__solver': [\"newton-cholesky\", \"saga\", \"lbfgs\", \"liblinear\"]\n",
        "}\n",
        "\n",
        "# logistic regression random search instance\n",
        "pipe_logreg_clf = RandomizedSearchCV(pipe, # pipeline containing the victorizer and model\n",
        "                                    params, # pipeline hyperparameters\n",
        "                                    cv=pds, # predefined split\n",
        "                                    scoring=\"roc_auc\", # scoring metric used to evaluate the validation data with it\n",
        "                                    n_iter=10, # number of trials (hyperparameters combinations to try)\n",
        "                                    verbose=1,)\n",
        "\n",
        "# model fitting and training using the training data (will use the optimal hyperparameters that will be found)\n",
        "# here we still use X_train; but the randomized search model will use our predefined split internally to determine\n",
        "# which sample belongs to the validation set\n",
        "pipe_logreg_clf.fit(X_tr, y_tr)\n",
        "pickle.dump(pipe_logreg_clf, open(\"./pipeline_clf_logreg.pck\", \"wb\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12141f39-5f17-4fcf-a34a-5652463fd2b9",
        "id": "6jsbrqONr5lm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "2 fits failed out of a total of 10.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "2 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/pipeline.py\", line 405, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
            "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 1061, in __call__\n",
            "    self.retrieve()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 938, in retrieve\n",
            "    self._output.extend(job.get(timeout=self.timeout))\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
            "    return future.result(timeout=timeout)\n",
            "  File \"/usr/lib/python3.9/concurrent/futures/_base.py\", line 446, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.9/concurrent/futures/_base.py\", line 391, in __get_result\n",
            "    raise self._exception\n",
            "joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n",
            "\n",
            "The exit codes of the workers are {SIGKILL(-9)}\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.85112815 0.82112787 0.85112431 0.85124123        nan        nan\n",
            " 0.85123223 0.78257686 0.82113406 0.85112501]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 24s, sys: 6.79 s, total: 2min 30s\n",
            "Wall time: 4min 9s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('best score {}'.format(pipe_logreg_clf.best_score_)) # getting the best validation AUC score\n",
        "\n",
        "best_params_logreg = pipe_logreg_clf.best_params_\n",
        "print('best hyperparameters {}'.format(best_params_logreg)) # getting the optimal hyperparameters values found"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6934954-a7a8-4394-b90f-2e802840dafc",
        "id": "idCBPtCMr5ln"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.8512412262282633\n",
            "best hyperparameters {'tfidf__ngram_range': (1, 4), 'tfidf__min_df': 5, 'tfidf__max_df': 0.7, 'logreg__solver': 'saga', 'logreg__penalty': 'l2', 'logreg__max_iter': 10000, 'logreg__C': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training on whole dataset"
      ],
      "metadata": {
        "id": "0RZJyYNcr5lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.set_params(**best_params_logreg).fit(X_tr, y_tr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "0ab76203-f4d2-49d1-8477-4a1d67ffa48f",
        "id": "O6hs1uigr5lp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='char', max_df=0.7, min_df=5,\n",
              "                                 ngram_range=(1, 4))),\n",
              "                ('logreg',\n",
              "                 LogisticRegression(C=10, max_iter=10000, n_jobs=2,\n",
              "                                    solver='saga'))])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
              "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, max_df=0.7, min_df=5,\n",
              "                                 ngram_range=(1, 4))),\n",
              "                (&#x27;logreg&#x27;,\n",
              "                 LogisticRegression(C=10, max_iter=10000, n_jobs=2,\n",
              "                                    solver=&#x27;saga&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
              "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, max_df=0.7, min_df=5,\n",
              "                                 ngram_range=(1, 4))),\n",
              "                (&#x27;logreg&#x27;,\n",
              "                 LogisticRegression(C=10, max_iter=10000, n_jobs=2,\n",
              "                                    solver=&#x27;saga&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, max_df=0.7, min_df=5, ngram_range=(1, 4))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, max_iter=10000, n_jobs=2, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing (Predictions of test set)"
      ],
      "metadata": {
        "id": "nk6eB4j4x6eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame()\n",
        "submission['id'] = test_data.index\n",
        "submission['label'] = pipe.predict_proba(test_data['comment_clean'])[:,1]\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "HNFkkyZCr5lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations and trial summary"
      ],
      "metadata": {
        "id": "t_BycXDXcJ8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Aspect**                                                | **Comment**                                                                                                                                                                                |\n",
        "|-----------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| _1- Model type_                                           | Logistic Regression                                                                                                                                                                        |\n",
        "| _2- Root-form preprocessing_                              | Stemming                                                                                                                                                                                   |\n",
        "| _3- Vectorizer_                                           | TF-IDF (**character** n-gram)                                                                                                                                                              |\n",
        "| _4- Hyperparameters tuner_                                | Randomized Search (using predefined validation set)                                                                                                                                        |\n",
        "| _5- Vectorizer hyperparameters space_                     | \"tfidf__ngram_range\": ((1, 2), (1, 3),(1,4)),<br>\"tfidf__max_df\": [0.5, 0.6, 0.7, 0.8, 0.9],<br>\"tfidf__min_df\": [5, 10, 20, 30, 50]                                                       |\n",
        "| _6- Model hyperparameters space_                          | 'logreg__penalty': [\"l2\"],<br>'logreg__C': [0.01, 0.1, 1,10],<br>'logreg__max_iter': [10000],<br>'logreg__solver': [\"newton-cholesky\", \"saga\", \"lbfgs\", \"liblinear\"]                       |\n",
        "| _7- Optimal hyperparameters_                             | 'tfidf__ngram_range': (1, 4),<br>'tfidf__min_df': 5,<br>'tfidf__max_df': 0.7,<br>'logreg__solver': 'saga', <br>'logreg__penalty': 'l2', <br>'logreg__max_iter': 10000, <br>'logreg__C': 10 |\n",
        "| _8- AUC score predefined validation set_                  | 0.8512                                                                                                                                                                                     |\n",
        "| _9- AUC score on kaggle test set (public)_                | 0.7983                                                                                                                                                                                     |\n",
        "| _10- Observed performance and thoughts on it_             | As expected the model is having lower performance than the previous case when we used word-level n-gram<br> this is typically because character-level ngrmas can not provide the model with accurate relations between the characters and their <br> sentiment meaning as a character level gram is indeed possible to appear in both negative and positive sentences, however in case<br>of word ngrams a word is more possible to be related to a sentiment meaning and therefore appears more on a specific class <br> in such case the model can learn the relation between the word and the label class better.                                                                                                                                                                                        |\n",
        "| _11- Reason for changes (if any) and plan for next trial_ | Next we will try another algorithm which XGboosting as it can act as a feature selection method which will benefit our model because <br>of the huge number of features that we have. We will stick with word n-gram with all the following trials.                                                                                                                                                                                       |"
      ],
      "metadata": {
        "id": "boP8fFSucJ34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3 XGboosting with TF-IDF vectorization (analyzer=word) and random search as hyperparameter tuner"
      ],
      "metadata": {
        "id": "7aCVl6AUg3sW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# feature creation and modelling in a single function\n",
        "# combine the victorizer with the model as a full tunable pipeline\n",
        "# we gave them a name so we can set their hyperparameters\n",
        "pipe = Pipeline(\n",
        "        steps = [(\"tfidf\", TfidfVectorizer(analyzer=\"word\")),\n",
        "                 (\"xgb\", XGBClassifier())]\n",
        ")\n",
        "\n",
        "# define parameter space to test\n",
        "# hyperparameters search space of both the model and preprocessing\n",
        "params = {\n",
        "    # victorizer hyperparameters (5*5*3 75 combination)\n",
        "    \"tfidf__ngram_range\": ((1, 2), (1, 3),(1,4)),\n",
        "    \"tfidf__max_df\": [0.5, 0.6, 0.7, 0.8, 0.9],\n",
        "    \"tfidf__min_df\": [5, 10, 20, 30, 50]\n",
        "}\n",
        "\n",
        "# logistic regression random search instance\n",
        "pipe_clf = RandomizedSearchCV(pipe, # pipeline containing the victorizer and model\n",
        "                              params, # pipeline hyperparameters\n",
        "                              cv=pds, # predefined split\n",
        "                              scoring=\"roc_auc\", # scoring metric used to evaluate the validation data with it\n",
        "                              n_iter=37, # number of trials (hyperparameters combinations to try)\n",
        "                              n_jobs=-1, # number of concurrent threads -1 means using all processors\n",
        "                              verbose=1,)\n",
        "\n",
        "# model fitting and training using the training data (will use the optimal hyperparameters that will be found)\n",
        "# here we still use X_tr; but the randomized search model will use our predefined split internally to determine\n",
        "# which sample belongs to the validation set\n",
        "pipe_clf.fit(X_tr, y_tr)\n",
        "pickle.dump(pipe_clf, open(\"./pipeline_clf_tfidf.pck\", \"wb\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca93c0be-e7de-4388-8c78-3a1dfbfd84c3",
        "id": "edwCAA3_izJx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 37 candidates, totalling 37 fits\n",
            "CPU times: user 1min 14s, sys: 1.24 s, total: 1min 15s\n",
            "Wall time: 15min 28s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('best score {}'.format(pipe_clf.best_score_)) # getting the best validation AUC score\n",
        "print('best hyperparameters {}'.format(pipe_clf.best_params_)) # getting the optimal hyperparameters values found"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b7f54c2-481a-4bd1-ca40-f72ab0bef698",
        "id": "Ofwt_IOhi27u"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.8291936442776718\n",
            "best hyperparameters {'tfidf__ngram_range': (1, 4), 'tfidf__min_df': 5, 'tfidf__max_df': 0.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, using this best parameters for TF-IDF we can search for optimal parameters for the LogisticRegression classifier:"
      ],
      "metadata": {
        "id": "5_VEEerBi6eE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# feature creation and modelling in a single function\n",
        "# combine the victorizer with the model as a full tunable pipeline\n",
        "# we gave them a name so we can set their hyperparameters\n",
        "pipe = Pipeline(\n",
        "        steps = [(\"tfidf\", TfidfVectorizer(analyzer=\"word\")),\n",
        "                 (\"xgb\", XGBClassifier(n_jobs=2))]\n",
        ")\n",
        "\n",
        "# define parameter space to test\n",
        "# hyperparameters search space of both the model and preprocessing\n",
        "params = {\n",
        "    # victorizer hyperparameters\n",
        "    \"tfidf__ngram_range\": [(1, 4)],\n",
        "    \"tfidf__max_df\": [0.5],\n",
        "    \"tfidf__min_df\": [5],\n",
        "    # model hyperparameters\n",
        "    'xgb__learning_rate': [0.01, 0.1],\n",
        "    'xgb__n_estimators': [100, 250, 500],\n",
        "    'xgb__subsample': [0.5, 0.8],\n",
        "    'xgb__colsample_bytree': [0.5, 0.8],\n",
        "    'xgb__booster': ['gbtree','gblinear', 'dart']\n",
        "}\n",
        "\n",
        "# logistic regression random search instance\n",
        "pipe_xgb_clf = RandomizedSearchCV(pipe, # pipeline containing the victorizer and model\n",
        "                                    params, # pipeline hyperparameters\n",
        "                                    cv=pds, # predefined split\n",
        "                                    scoring=\"roc_auc\", # scoring metric used to evaluate the validation data with it\n",
        "                                    n_iter=36, # number of trials (hyperparameters combinations to try)\n",
        "                                    verbose=1,)\n",
        "\n",
        "# model fitting and training using the training data (will use the optimal hyperparameters that will be found)\n",
        "# here we still use X_tr; but the randomized search model will use our predefined split internally to determine\n",
        "# which sample belongs to the validation set\n",
        "pipe_xgb_clf.fit(X_tr, y_tr)\n",
        "pickle.dump(pipe_xgb_clf, open(\"./pipeline_clf_xgb.pck\", \"wb\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34e25561-d44b-4558-97dc-54df2e58e5ad",
        "id": "LwQIkH9KjAnd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 36 candidates, totalling 36 fits\n",
            "[04:52:35] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"colsample_bytree\", \"subsample\" } are not used.\n",
            "\n",
            "[05:03:52] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"colsample_bytree\", \"subsample\" } are not used.\n",
            "\n",
            "[05:04:01] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"colsample_bytree\", \"subsample\" } are not used.\n",
            "\n",
            "[05:04:43] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"colsample_bytree\", \"subsample\" } are not used.\n",
            "\n",
            "[05:04:50] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"colsample_bytree\", \"subsample\" } are not used.\n",
            "\n",
            "[05:16:09] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"colsample_bytree\", \"subsample\" } are not used.\n",
            "\n",
            "[05:17:20] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"colsample_bytree\", \"subsample\" } are not used.\n",
            "\n",
            "[05:17:28] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"colsample_bytree\", \"subsample\" } are not used.\n",
            "\n",
            "[05:32:41] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"colsample_bytree\", \"subsample\" } are not used.\n",
            "\n",
            "[05:40:31] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"colsample_bytree\", \"subsample\" } are not used.\n",
            "\n",
            "[05:41:17] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"colsample_bytree\", \"subsample\" } are not used.\n",
            "\n",
            "[06:01:27] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"colsample_bytree\", \"subsample\" } are not used.\n",
            "\n",
            "CPU times: user 1h 57min 56s, sys: 22.7 s, total: 1h 58min 19s\n",
            "Wall time: 1h 9min 7s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('best score {}'.format(pipe_xgb_clf.best_score_)) # getting the best validation AUC score\n",
        "\n",
        "best_params_xgb = pipe_xgb_clf.best_params_\n",
        "print('best hyperparameters {}'.format(best_params_xgb)) # getting the optimal hyperparameters values found"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "503610fa-d96b-4ece-8f02-f6edddd0cc9c",
        "id": "RT2TwMgEjF7W"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score 0.858952818609237\n",
            "best hyperparameters {'xgb__subsample': 0.5, 'xgb__n_estimators': 100, 'xgb__learning_rate': 0.01, 'xgb__colsample_bytree': 0.8, 'xgb__booster': 'gblinear', 'tfidf__ngram_range': (1, 4), 'tfidf__min_df': 5, 'tfidf__max_df': 0.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training on whole dataset"
      ],
      "metadata": {
        "id": "AYVlVfS-jKrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.set_params(**best_params_xgb).fit(X_tr, y_tr)"
      ],
      "metadata": {
        "id": "1z3vLVBKjPhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing (Predictions of test set)"
      ],
      "metadata": {
        "id": "cMM-SUlHjSv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame()\n",
        "submission['id'] = test_data.index\n",
        "submission['label'] = pipe.predict_proba(test_data['comment_clean'])[:,1]\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "UhwlvmYjjVgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations and trial summary"
      ],
      "metadata": {
        "id": "0v4VJhrwc_Bl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Aspect**                                                | **Comment**                                                                                                                                                                                                                        |\n",
        "|-----------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| _1- Model type_                                           | XGBoosting                                                                                                                                                                                                                         |\n",
        "| _2- Root-form preprocessing_                              | Stemming                                                                                                                                                                                                                           |\n",
        "| _3- Vectorizer_                                           | TF-IDF (word n-gram)                                                                                                                                                                                                               |\n",
        "| _4- Hyperparameters tuner_                                | Randomized Search (using predefined validation set)                                                                                                                                                                                |\n",
        "| _5- Vectorizer hyperparameters space_                     | \"tfidf__ngram_range\": ((1, 2), (1, 3),(1,4)),<br>\"tfidf__max_df\": [0.5, 0.6, 0.7, 0.8, 0.9],<br>\"tfidf__min_df\": [5, 10, 20, 30, 50]                                                                                               |\n",
        "| _6- Model hyperparameters space_                          | 'xgb__learning_rate': [0.01, 0.1],<br>'xgb__n_estimators': [100, 250, 500]<br>'xgb__subsample': [0.5, 0.8],<br>'xgb__colsample_bytree': [0.5, 0.8],<br>'xgb__booster': ['gbtree','gblinear', 'dart']                               |\n",
        "| _7- Optimal hyper parameters_                             | 'xgb__subsample': 0.5,<br>'xgb__n_estimators': 100,<br>'xgb__learning_rate': 0.01,<br>'xgb__colsample_bytree': 0.8,<br>'xgb__booster': 'gblinear',<br>'tfidf__ngram_range': (1, 4),<br>'tfidf__min_df': 5,<br>'tfidf__max_df': 0.5 |\n",
        "| _8- AUC score predefined validation set_                  | 0.8590                                                                                                                                                                                                                             |\n",
        "| _9- AUC score on kaggle test set (public)_                | 0.8056                                                                                                                                                                                                                             |\n",
        "| _10- Observed performance and thoughts on it_             | Astonishingly the model is having lower performance than the first trial of logistic regression<br> whic is something that we dont expect as usually XGboosting is capable of dealing with huge numbers<br> of features, and usually XGboosting was one of the best classifiers that i have tried. I suspect this behaviour<br> to be due to hyperparameters as we used Randomized Search and it is very possible that we could have <br> missed the optimal values. Our choice for Randomized Search from the first place was in sake of faster training time.                                                                                                                                                                                                                               |\n",
        "| _11- Reason for changes (if any) and plan for next trial_ | Next we will try another preprocessing technique which lemmatization which returns the word to its dictionary-based root. <br> we expect this to have better performance than stemming as we read that it is usually has better accuracy than stemming<br> in cases where context is important so we will test it on the same classifiers to check this claim.                                                                                                                                                                                                                               |"
      ],
      "metadata": {
        "id": "YZlb_B72dAUg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.2-** Case 2: Models trained on data preprocessed using ***Lemmatization***"
      ],
      "metadata": {
        "id": "JaQ2lzSj8MFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-processing re-do for lemmatization case"
      ],
      "metadata": {
        "id": "T_X7lIbG471_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import PredefinedSplit\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "qbCdaSnA1BLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c3395e0-e25e-4786-cb0c-83e89f4e49ea",
        "id": "XjkWAt0H1Eo6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        label  \\\n",
            "id              \n",
            "265723      0   \n",
            "284269      0   \n",
            "207715      0   \n",
            "551106      0   \n",
            "8584        0   \n",
            "\n",
            "                                                                                                title_clean  \n",
            "id                                                                                                           \n",
            "265723  group friend began volunteer homeless shelter neighbor protested seeing another person also need...  \n",
            "284269  british prime minister theresa may nerve attack former russian spy government concluded highly l...  \n",
            "207715  goodyear released kit allows p brought heel http youtube com watch alxulk cg zwillc fishing mida...  \n",
            "551106  happy birthday bob barker price right host like remembered man said ave pet spayed neutered fuck...  \n",
            "8584    obama nation innocent cop unarmed young black men dying magic johnson jimbobshawobodob olympic a...  \n",
            "X_train shape: (44818,)\n",
            "X_valid shape: (14940,)\n"
          ]
        }
      ],
      "source": [
        "# Clean titles for training and testing\n",
        "train_data_clean_lemm[\"title_clean\"] = train_data_clean_lemm[\"text\"].map(lambda x: clean_text(x, root_form = \"lemmatization\", for_embedding=False) if isinstance(x, str) else x)\n",
        "test_data_lemm[\"title_clean\"] = test_data_lemm[\"text\"].map(lambda x: clean_text(x, root_form = \"lemmatization\", for_embedding=False) if isinstance(x, str) else x)\n",
        "\n",
        "# Drop when any of x missing\n",
        "train_data_clean_lemm = train_data_clean_lemm[(train_data_clean_lemm[\"title_clean\"] != \"\") & (train_data_clean_lemm[\"title_clean\"] != \"null\")]\n",
        "\n",
        "# Remove column name 'text'\n",
        "train_data_clean_lemm = train_data_clean_lemm.drop(['text'], axis=1)\n",
        "test_data_lemm = test_data_lemm.drop(['text'], axis=1)\n",
        "\n",
        "# Checking the dataframe\n",
        "print(train_data_clean_lemm.head(5))\n",
        "\n",
        "# split the original training set to a train and a validation set - 25% of data as validation\n",
        "train, valid = train_test_split(train_data_clean_lemm, stratify=train_data_clean_lemm['label'], random_state=1, test_size=0.25, shuffle=True)\n",
        "X_train = train[\"title_clean\"]\n",
        "y_train = train[\"label\"]\n",
        "X_valid = valid[\"title_clean\"]\n",
        "y_valid = valid[\"label\"]\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_valid shape:\", X_valid.shape)\n",
        "\n",
        "# Create a list where train data indices are -1 and validation data indices are 0\n",
        "# X_train2 (new training set), X_train\n",
        "split_index = [-1 if x in X_train.index else 0 for x in train_data_clean_lemm.index]\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "pds = PredefinedSplit(test_fold = split_index)\n",
        "\n",
        "y_tr = train_data_clean_lemm[\"label\"] # target label series\n",
        "X_tr = train_data_clean_lemm[\"title_clean\"] # training features df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_lemm.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "DWIXUHKJ81Ae",
        "outputId": "bcae476c-8ea6-45b3-a58d-9e20a674de1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           title_clean\n",
              "id                                                    \n",
              "0                                            stargazer\n",
              "1                                                 yeah\n",
              "2   pd phoenix car thief get instruction youtube video\n",
              "3           trump accuses iran one problem credibility\n",
              "4                                   believer hezbollah"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1c4681f-2763-49d5-8063-70d2051f5e3d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title_clean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>stargazer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yeah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pd phoenix car thief get instruction youtube video</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>trump accuses iran one problem credibility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>believer hezbollah</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1c4681f-2763-49d5-8063-70d2051f5e3d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d1c4681f-2763-49d5-8063-70d2051f5e3d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d1c4681f-2763-49d5-8063-70d2051f5e3d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4 Logistic Regression with TF-IDF vectorization (analyzer=word) and random search as hyperparameter tuner ‚≠ê‚≠ê‚≠ê"
      ],
      "metadata": {
        "id": "N3wzPUm85yaG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizing the feature creation (vectorization) step through trying different values for ngram, max_df and min_df where the last two parameters set an upper and lower limit for word frequencies."
      ],
      "metadata": {
        "id": "KV3g85485yaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# feature creation and modelling in a single function\n",
        "# combine the victorizer with the model as a full tunable pipeline\n",
        "# we gave them a name so we can set their hyperparameters\n",
        "pipe = Pipeline(\n",
        "        steps = [(\"tfidf\", TfidfVectorizer(analyzer=\"word\")),\n",
        "                 (\"logreg\", LogisticRegression(n_jobs=-1))]\n",
        ")\n",
        "\n",
        "# define parameter space to test\n",
        "# hyperparameters search space of both the model and preprocessing\n",
        "params = {\n",
        "    # victorizer hyperparameters (5*5*3 75 combination)\n",
        "    \"tfidf__ngram_range\": ((1, 2), (1, 3),(1,4), (1,5)),\n",
        "    \"tfidf__max_df\": [0.5, 0.6, 0.7, 0.8, 0.9],\n",
        "    \"tfidf__min_df\": [5, 10, 20, 30]\n",
        "}\n",
        "\n",
        "# logistic regression random search instance\n",
        "pipe_clf = RandomizedSearchCV(pipe, # pipeline containing the victorizer and model\n",
        "                              params, # pipeline hyperparameters\n",
        "                              cv=pds, # predefined split\n",
        "                              scoring=\"roc_auc\", # scoring metric used to evaluate the validation data with it\n",
        "                              n_iter=37, # number of trials (hyperparameters combinations to try)\n",
        "                              verbose=1,)\n",
        "\n",
        "# model fitting and training using the training data (will use the optimal hyperparameters that will be found)\n",
        "# here we still use X_tr; but the randomized search model will use our predefined split internally to determine\n",
        "# which sample belongs to the validation set\n",
        "pipe_clf.fit(X_tr, y_tr)\n",
        "pickle.dump(pipe_clf, open(\"./pipeline_clf_tfidf_lemm.pck\", \"wb\"))"
      ],
      "metadata": {
        "id": "mjOrqAOW5yaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('best score {}'.format(pipe_clf.best_score_)) # getting the best validation AUC score\n",
        "print('best hyperparameters {}'.format(pipe_clf.best_params_)) # getting the optimal hyperparameters values found"
      ],
      "metadata": {
        "id": "Kk3xWH5V5yaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, using this best parameters for TF-IDF we can search for optimal parameters for the LogisticRegression classifier:"
      ],
      "metadata": {
        "id": "xmu7VLjL5yaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# feature creation and modelling in a single function\n",
        "# combine the victorizer with the model as a full tunable pipeline\n",
        "# we gave them a name so we can set their hyperparameters\n",
        "pipe = Pipeline(\n",
        "        steps = [(\"tfidf\", TfidfVectorizer(analyzer=\"word\")),\n",
        "                 (\"logreg\", LogisticRegression(n_jobs=-1))]\n",
        ")\n",
        "\n",
        "# define parameter space to test # runtime 35min\n",
        "# hyperparameters search space of both the model and preprocessing\n",
        "params = {\n",
        "    # victorizer hyperparameters\n",
        "    \"tfidf__ngram_range\": [(1, 4)],\n",
        "    \"tfidf__max_df\": [0.9],\n",
        "    \"tfidf__min_df\": [5],\n",
        "    # model hyperparameters\n",
        "    'logreg__penalty': [\"l2\"],\n",
        "    'logreg__C': [0.01, 0.1, 1,10],\n",
        "    'logreg__max_iter': [10000],\n",
        "    'logreg__solver': [\"newton-cholesky\", \"saga\", \"lbfgs\", \"liblinear\"]\n",
        "}\n",
        "\n",
        "# logistic regression random search instance\n",
        "pipe_logreg_clf = RandomizedSearchCV(pipe, # pipeline containing the victorizer and model\n",
        "                                    params, # pipeline hyperparameters\n",
        "                                    cv=pds, # predefined split\n",
        "                                    scoring=\"roc_auc\", # scoring metric used to evaluate the validation data with it\n",
        "                                    n_iter=10, # number of trials (hyperparameters combinations to try)\n",
        "                                    verbose=1,)\n",
        "\n",
        "# model fitting and training using the training data (will use the optimal hyperparameters that will be found)\n",
        "# here we still use X_train; but the grid search model\n",
        "# will use our predefined split internally to determine\n",
        "# which sample belongs to the validation set\n",
        "pipe_logreg_clf.fit(X_tr, y_tr)\n",
        "pickle.dump(pipe_logreg_clf, open(\"./pipeline_clf_logreg_lemm.pck\", \"wb\"))"
      ],
      "metadata": {
        "id": "eN8kzy0D5yaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('best score {}'.format(pipe_logreg_clf.best_score_)) # getting the best validation AUC score\n",
        "\n",
        "best_params_logreg = pipe_logreg_clf.best_params_\n",
        "print('best hyperparameters {}'.format(best_params_logreg)) # getting the optimal hyperparameters values found"
      ],
      "metadata": {
        "id": "_eSi1Oxx5yaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training on whole dataset"
      ],
      "metadata": {
        "id": "ldHcc3Qb5yaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.set_params(**best_params_logreg).fit(X_tr, y_tr)"
      ],
      "metadata": {
        "id": "UjMsG9vP5yaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing (Predictions of test set)"
      ],
      "metadata": {
        "id": "qFVcgPKU5yaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame()\n",
        "submission['id'] = test_data_lemm.index\n",
        "submission['label'] = pipe.predict_proba(test_data_lemm['title_clean'])[:,1]\n",
        "submission.to_csv('submission_4.csv', index=False)"
      ],
      "metadata": {
        "id": "Tm9GdexF5yaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations and trial summary"
      ],
      "metadata": {
        "id": "BVKoIQFBfKUI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Unfortunately cells output has been gone for this trial as I pressed the run button of the model subsection by mistake while I was editing the header and not being connected to runtime but luckily I had already filled the below summary table.***"
      ],
      "metadata": {
        "id": "ktBLgDeymuVv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Aspect**                                                | **Comment**                                                                                                                                                                                               |\n",
        "|-----------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| _1- Model type_                                           | Logistic Regression                                                                                                                                                                                       |\n",
        "| _2- Root-form preprocessing_                              | Lemmatization                                                                                                                                                                                             |\n",
        "| _3- Vectorizer_                                           | TF-IDF (word n-gram)                                                                                                                                                                                      |\n",
        "| _4- Hyperparameters tuner_                                | Randomized Search (using predefined validation set)                                                                                                                                                       |\n",
        "| _5- Vectorizer hyperparameters space_                     | \"tfidf__ngram_range\": ((1, 2), (1, 3),(1,4),(1,5)), ---> added (1,5) to search space<br>\"tfidf__max_df\": [0.5, 0.6, 0.7, 0.8, 0.9],<br>\"tfidf__min_df\": [5, 10, 20, 30] ---> removed 50 from search space |\n",
        "| _6- Model hyperparameters space_                          | 'logreg__penalty': [\"l2\"],<br>'logreg__C': [0.01, 0.1, 1,10],<br>'logreg__max_iter': [10000],<br>'logreg__solver': [\"newton-cholesky\", \"saga\", \"lbfgs\", \"liblinear\"]                                      |\n",
        "| _7- Optimal hyper parameters_                             | 'tfidf__ngram_range': (1, 4),<br>'tfidf__min_df': 5,<br>'tfidf__max_df': 0.9,<br>'logreg__solver': 'newton-cholesky',<br>'logreg__penalty': 'l2',<br>'logreg__max_iter': 10000,<br>'logreg__C': 1         |\n",
        "| _8- AUC score predefined validation set_                  | 0.8720                                                                                                                                                                                                    |\n",
        "| _9- AUC score on kaggle test set (public)_                | 0.8404                                                                                                                                                                                                    |\n",
        "| _10- Observed performance and thoughts on it_             | As claimed the lemmatization is better than stemming! this model is the best performer on both validation set<br> and Kaggle's testing set. This can be due to the fact that lemmatization gives more context to the model as it <br>recognizes words based on their exact and contextual meaning and not just cutting the word as in case of stemming <br>which may also suffer from overstemming or understemming.                                                                                                                                                                                                      |\n",
        "| _11- Reason for changes (if any) and plan for next trial_ | Next we will try XGboosting again using lemmatized data and hopefully the score will improve as it did with logistic regression.                                                                                                                                                                                                      |"
      ],
      "metadata": {
        "id": "xi9xyH2pfLaD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 5 XGboosting with TF-IDF vectorization (analyzer=word)"
      ],
      "metadata": {
        "id": "pc7c03h3F53u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "best hyperparameters {'xgb__subsample': 0.5,\n",
        "'xgb__n_estimators': 100,\n",
        "'xgb__learning_rate': 0.01,\n",
        "'xgb__colsample_bytree': 0.8,\n",
        "'xgb__booster': 'gblinear',\n",
        "'tfidf__ngram_range': (1, 4),\n",
        "'tfidf__min_df': 5,\n",
        "'tfidf__max_df': 0.5}\n"
      ],
      "metadata": {
        "id": "Czt-g9CdNvuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_tfidf = TfidfVectorizer(analyzer=\"word\",\n",
        "                                 max_df=0.5,\n",
        "                                 min_df=5,\n",
        "                                 ngram_range=(1, 4),\n",
        "                                 norm = \"l2\")\n",
        "vectorizer_tfidf.fit(X_tr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "MGqCmzGZHHjN",
        "outputId": "693c51b2-db5f-417f-da30-32a66913176b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(max_df=0.5, min_df=5, ngram_range=(1, 4))"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_df=0.5, min_df=5, ngram_range=(1, 4))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.5, min_df=5, ngram_range=(1, 4))</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transform each sentence to numeric vector with tf-idf value as elements\n",
        "\n",
        "X_tr_vec = vectorizer_tfidf.transform(X_tr)\n",
        "X_test_vec = vectorizer_tfidf.transform(test_data_lemm['title_clean'])\n",
        "\n",
        "X_tr_vec.get_shape()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-1RmsPsHSSJ",
        "outputId": "ff7cb7d7-66b5-49a4-b86e-4c238a1954ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59758, 23374)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_clf = XGBClassifier(subsample=0.5,\n",
        "                            n_estimators=100,\n",
        "                            learning_rate= 0.01,\n",
        "                            colsample_bytree=0.8,\n",
        "                            booster = 'gblinear',\n",
        "                            n_jobs=-1)\n",
        "\n",
        "xgb_clf.fit(X_tr_vec,y_tr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "eTAThQoFHV3b",
        "outputId": "217e7a6c-9b1f-40d4-b8c0-bf6fcd3c7041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:15:09] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"colsample_bytree\", \"subsample\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster='gblinear', callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.8, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=&#x27;gblinear&#x27;, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.8, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gblinear&#x27;, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.8, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing (Predictions of test set)"
      ],
      "metadata": {
        "id": "f-0S9QvMF536"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame()\n",
        "submission['id'] = test_data_lemm.index\n",
        "submission['label'] = xgb_clf.predict_proba(X_test_vec)[:,1]\n",
        "submission.to_csv('submission_5_2.csv', index=False)"
      ],
      "metadata": {
        "id": "FohW6RCrF536"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations and trial summary"
      ],
      "metadata": {
        "id": "aMlgQRpvfNCj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Aspect**                                                | **Comment**                                                                                                                                                                                                                        |\n",
        "|-----------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| _1- Model type_                                           | XGBoosting                                                                                                                                                                                                                         |\n",
        "| _2- Root-form preprocessing_                              | Lemmatization                                                                                                                                                                                                                           |\n",
        "| _3- Vectorizer_                                           | TF-IDF (word n-gram)                                                                                                                                                                                                               |\n",
        "| _4- Hyperparameters tuner_                                | None - will use previous XGBoosting trial hyperparameters                                                                                                                                                                          |\n",
        "| _5- Vectorizer hyperparameters space_                     | None                                                                                                                                                                                                                               |\n",
        "| _6- Model hyperparameters space_                          | None                                                                                                                                                                                                                               |\n",
        "| _7- Optimal hyper parameters_                             | 'xgb__subsample': 0.5,<br>'xgb__n_estimators': 100,<br>'xgb__learning_rate': 0.01,<br>'xgb__colsample_bytree': 0.8,<br>'xgb__booster': 'gblinear',<br>'tfidf__ngram_range': (1, 4),<br>'tfidf__min_df': 5,<br>'tfidf__max_df': 0.5 |\n",
        "| _8- AUC score predefined validation set_                  | None - didn't use validation trained on whole data directly                                                                                                                                                                        |\n",
        "| _9- AUC score on kaggle test set (public)_                | 0.8087                                                                                                                                                                                                                             |\n",
        "| _10- Observed performance and thoughts on it_             | The claim that lemmatization has better performnace than stemming still holds in this case as well, <br>as the performance at this trial is better than trial 3 in which we used XGboosting with stemming which had<br> testing AUC of 0.8056.Although we didn't use hyperparameters tuner and just relied on the obtained parameters <br>from the 3rd trial as tuning the XBboosting model took long time, the model still performed better than the stemming case.                                                                                                                                                                                                                                |\n",
        "| _11- Reason for changes (if any) and plan for next trial_ | As shown lemmatization AUC score is better than stemming even when using not that optimal hyperparameters,<br> so a possible setup for a next trial can be using using hyperparameter tuner to get the optimal values for the XGboosting <br>model which will indeed have a higher AUC score than this trial.                                                                                                                                                                                                                                |"
      ],
      "metadata": {
        "id": "ArEPvDmMfOHw"
      }
    }
  ]
}